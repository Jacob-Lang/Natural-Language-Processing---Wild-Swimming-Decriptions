{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wild Swimming - Data Acquisition\n",
    "\n",
    "In this project I use natural language processing to cluster descriptions of wild swimming locations. To do this I need a dataset of wild swimming location descriptions. Luckily for me, there is such a database here: http://www.wildswimming.co.uk/wild-swim-map-uk/?multi_region=wild-swim-map-uk . However, I need to scrape this data from the website before I can start work on it. \n",
    "\n",
    "I can do this using the web scraping skills I developed in my previous project \"Web-Scraping---Fantasy-F1\". I will use BeautifulSoup to scrape the text data. (The differnent locations have a separate webpage each so I don't need to use Selenium to deal with JavaScript elements like i did before.) I will store this information in a pandas dataframe then save to csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# packages for web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wild swimming website contains a list of wild swimming locations with links to a separate page for each location:  \n",
    "\n",
    "e.g.http://www.wildswimming.co.uk/map/spitchwick-common/  \n",
    "\n",
    "On the separate web pages there is a text description about the wild swim location:  \n",
    "\n",
    "e.g. *Peaty water, clean from the mountain, this is the most popular and accessible Dart swimming location, especially in \n",
    "summer. Also known as Deeper Marsh, it has been a bathing place for generations. Grassy flats lead to rocky river shore, deeper on far side with high cliff behind.*  \n",
    "\n",
    "These individual descriptions (one for each wild swim location) shall be the individual documents of my corpus. \n",
    "\n",
    "First we need to set up BeautifulSoup on the corpus webpage (again http://www.wildswimming.co.uk/wild-swim-map-uk/?multi_region=wild-swim-map-uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# website with the list of all wild swimming locations (the corpus)\n",
    "corpus_website = \"http://www.wildswimming.co.uk/wild-swim-map-uk/?multi_region=wild-swim-map-uk\"\n",
    "\n",
    "# get page with requests package and make 'soup' from it\n",
    "# can search throught the 'soup' for elements of the webpage\n",
    "corpus_page = requests.get(corpus_website)\n",
    "corpus_soup = BeautifulSoup(corpus_page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the list of locations, how many locations there are and the individual links for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 200 different wild swimming locations listed in the database\n",
      "An example link found on the corpus webpage: http://www.wildswimming.co.uk/map/spitchwick-common/\n"
     ]
    }
   ],
   "source": [
    "locations = corpus_soup.find(\"ul\", class_ = \"category_list_view clearfix\").find_all(\"li\", class_ = \"clearfix\")\n",
    "\n",
    "N_locations = len(locations)\n",
    "print(\"There are\", N_locations, \"different wild swimming locations listed in the database\")\n",
    "\n",
    "# finding the links for each \n",
    "n = 3\n",
    "document_website = locations[n].find(\"a\")['href']  # webpage found here.\n",
    "print(\"An example link found on the corpus webpage:\", document_website)\n",
    "\n",
    "# do same as earlier but for each page with the location desscription on (the documents)\n",
    "document_webpage = locations[n].find(\"a\")['href']  # webpage found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the link we can use BeautifulSoup again to find the text description (the document) and the location name (the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Name:  Spitchwick Common \n",
      "Description:  Peaty water, clean from the mountain, this is the most popular and accessible Dart swimming location, especially in summer. Also known as Deeper Marsh, it has been a bathing place for generations. Grassy flats lead to rocky river shore, deeper on far side with high cliff behind.\n"
     ]
    }
   ],
   "source": [
    "# set up BeautifulSoup on new page\n",
    "document_page = requests.get(document_webpage)\n",
    "document_soup = BeautifulSoup(document_page.text, 'html.parser')\n",
    "\n",
    "# find document and label\n",
    "label = document_soup.find(\"h1\", class_ = \"main_title\").find(\"a\").contents[0]   # document label found here\n",
    "document = document_soup.find(\"div\", class_ = \"posts post_spacer\").find(\"p\").contents[0]   # document found here\n",
    "\n",
    "print(\"Location Name:\", label)\n",
    "print(\"Description:\", document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how this matches what we expected from following the links before.  \n",
    "\n",
    "Now all we need to do is to loop over all links on the in the corpus webpage. I'll store the data in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dataframe to fill with data\n",
    "data = {'Location Name':  [],\n",
    "        'Description': [] }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# loop through wild swim locations\n",
    "for n in range(N_locations):\n",
    "    \n",
    "    if n == 37:         # for some reason this link does not work. http://www.wildswimming.co.uk/map/silent-pool-and-bolder-mere/\n",
    "        continue        # all the others are fine so I'll just skip this one. \n",
    "    \n",
    "    # navigate to page and get soup\n",
    "    document_webpage = locations[n].find(\"a\")['href']  # webpage found here.\n",
    "    document_page = requests.get(document_webpage)\n",
    "    document_soup = BeautifulSoup(document_page.text, 'html.parser')\n",
    "    \n",
    "    # extract document and label from soup\n",
    "    label = document_soup.find(\"h1\", class_ = \"main_title\").find(\"a\").contents[0]   # document label found here\n",
    "    document = document_soup.find(\"div\", class_ = \"posts post_spacer\").find(\"p\").contents[0]   # document found here\n",
    "\n",
    "    # append to dataframe\n",
    "    df = df.append({'Location Name': label, 'Description': document}, ignore_index=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go. Now we have all the data off the website and stored in a handy dataframe. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cornish Tipi Holidays</td>\n",
       "      <td>A luscious, chalk-green, spring-fed quarry lak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colliford Lake and Dozmary</td>\n",
       "      <td>A huge moorland lake, the highest and largest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>St Nectan’s Kieve</td>\n",
       "      <td>A tall, slender Waterfall or Gorge at the head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spitchwick Common</td>\n",
       "      <td>Peaty water, clean from the mountain, this is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Respryn Bridge</td>\n",
       "      <td>Wooded National Trust estate riverside walk. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bodmin Parkway</td>\n",
       "      <td>Still in the Lanhydrock Estate, this swim is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Holne Pool</td>\n",
       "      <td>Small Waterfall or Gorge with sunbathing rock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Golitha Falls</td>\n",
       "      <td>Beautiful stream of young river Fowey runs thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chagford Lido, Teign</td>\n",
       "      <td>River-fed swimming pool with cafﾎ set in field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wellsfoot Island</td>\n",
       "      <td>Wonderful wooded island with red sand beach sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Location Name  \\\n",
       "0        Cornish Tipi Holidays    \n",
       "1   Colliford Lake and Dozmary    \n",
       "2            St Nectan’s Kieve    \n",
       "3            Spitchwick Common    \n",
       "4               Respryn Bridge    \n",
       "5               Bodmin Parkway    \n",
       "6                   Holne Pool    \n",
       "7                Golitha Falls    \n",
       "8         Chagford Lido, Teign    \n",
       "9             Wellsfoot Island    \n",
       "\n",
       "                                         Description  \n",
       "0  A luscious, chalk-green, spring-fed quarry lak...  \n",
       "1  A huge moorland lake, the highest and largest ...  \n",
       "2  A tall, slender Waterfall or Gorge at the head...  \n",
       "3   Peaty water, clean from the mountain, this is...  \n",
       "4  Wooded National Trust estate riverside walk. S...  \n",
       "5  Still in the Lanhydrock Estate, this swim is o...  \n",
       "6  Small Waterfall or Gorge with sunbathing rock ...  \n",
       "7  Beautiful stream of young river Fowey runs thr...  \n",
       "8  River-fed swimming pool with cafﾎ set in field...  \n",
       "9  Wonderful wooded island with red sand beach sh...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just need to save it to a .csv for use in the rest of my project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"corpus.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
